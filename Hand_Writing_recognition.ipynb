{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hand_Writing_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DJ1070/Deep_Learning_Handwriting/blob/main/Hand_Writing_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_hzfVFMmU2E"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyV7Pipqt2mp"
      },
      "source": [
        "# mnist dataset : https://keras.io/api/datasets/mnist/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5elUylJmaJf",
        "outputId": "9f47d49a-9bd9-42f8-83ad-70b586ffb509"
      },
      "source": [
        "(x_train, y_train) ,(x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mo-NUzL_tac"
      },
      "source": [
        "**Sample From The Dataset** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "pThJv4NosXh7",
        "outputId": "046bbe33-ec3c-46c0-d399-ffa9431e81b4"
      },
      "source": [
        "plt.imshow(x_train[7]) # 28 X 28 images"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa307e29bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1j5XolusaPt",
        "outputId": "474c437d-4829-4ddd-a9eb-6db480baec8f"
      },
      "source": [
        "y_train[7]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVveqVK8_2ni"
      },
      "source": [
        "# \"Translation\" Of The Pictures Into Grayscale Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOkpkAJsx8rP"
      },
      "source": [
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEMLekL_AMyy"
      },
      "source": [
        "**Sample Of The First Digit In The Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iR8Y245zqWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac88d2d-f74e-41e5-9ab9-a2924738cbb9"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
              "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
              "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
              "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
              "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
              "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
              "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
              "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
              "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
              "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
              "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
              "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
              "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
              "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
              "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
              "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
              "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
              "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_EIQaSnzDLA"
      },
      "source": [
        "# Flatten: Used To Convert N-Dimensional Arrays to 1D-Arrays\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WASzwylEujqO"
      },
      "source": [
        "model = models.Sequential(\n",
        "    [\n",
        "    layers.Flatten(input_shape = (28,28)),\n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    #layers.Dropout(0.2),\n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    #layers.Dropout(0.2),\n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    #layers.Dropout(0.2),\n",
        "    layers.Dense(10, activation = 'softmax' )\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I2NFgmEAkaC"
      },
      "source": [
        "# Model Definition With Dropout Rate, Optimizer, sparse_categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F8al_C1AhVm"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = 'adam', \n",
        "    loss = 'sparse_categorical_crossentropy',  # binary_crossentropy, categorical_crossentropy\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yt5uoK5yZeT",
        "outputId": "bf4613c2-08ee-4364-dbdd-01abf4917983"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSRHYIviB2ca"
      },
      "source": [
        "# Fitting / Training - But Without The Necessary Validation Split "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxV4SgU1xDXq",
        "outputId": "0d8f8af9-a903-4ad2-fb65-4f848a5bbce0"
      },
      "source": [
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 50,\n",
        "    batch_size = 64\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "938/938 [==============================] - 5s 2ms/step - loss: 0.4617 - accuracy: 0.8635\n",
            "Epoch 2/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.1063 - accuracy: 0.9675\n",
            "Epoch 3/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0698 - accuracy: 0.9791\n",
            "Epoch 4/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0542 - accuracy: 0.9820\n",
            "Epoch 5/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0397 - accuracy: 0.9866\n",
            "Epoch 6/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0326 - accuracy: 0.9890\n",
            "Epoch 7/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0265 - accuracy: 0.9915\n",
            "Epoch 8/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0259 - accuracy: 0.9913\n",
            "Epoch 9/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0248 - accuracy: 0.9915\n",
            "Epoch 10/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0160 - accuracy: 0.9951\n",
            "Epoch 11/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0170 - accuracy: 0.9941\n",
            "Epoch 12/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0168 - accuracy: 0.9944\n",
            "Epoch 13/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0164 - accuracy: 0.9948\n",
            "Epoch 14/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0132 - accuracy: 0.9955\n",
            "Epoch 15/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0145 - accuracy: 0.9955\n",
            "Epoch 16/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0129 - accuracy: 0.9960\n",
            "Epoch 17/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0143 - accuracy: 0.9951\n",
            "Epoch 18/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0110 - accuracy: 0.9966\n",
            "Epoch 19/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0101 - accuracy: 0.9966\n",
            "Epoch 20/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0084 - accuracy: 0.9972\n",
            "Epoch 21/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0107 - accuracy: 0.9965\n",
            "Epoch 22/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0076 - accuracy: 0.9975\n",
            "Epoch 23/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0077 - accuracy: 0.9975\n",
            "Epoch 24/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0132 - accuracy: 0.9956\n",
            "Epoch 25/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0084 - accuracy: 0.9972\n",
            "Epoch 26/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0061 - accuracy: 0.9984\n",
            "Epoch 27/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0116 - accuracy: 0.9961\n",
            "Epoch 28/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0103 - accuracy: 0.9969\n",
            "Epoch 29/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0054 - accuracy: 0.9981\n",
            "Epoch 30/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0068 - accuracy: 0.9978\n",
            "Epoch 31/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0043 - accuracy: 0.9987\n",
            "Epoch 32/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0049 - accuracy: 0.9986\n",
            "Epoch 33/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0073 - accuracy: 0.9979\n",
            "Epoch 34/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0061 - accuracy: 0.9980\n",
            "Epoch 35/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0094 - accuracy: 0.9970\n",
            "Epoch 36/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0054 - accuracy: 0.9985\n",
            "Epoch 37/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0039 - accuracy: 0.9987\n",
            "Epoch 38/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - accuracy: 0.9971\n",
            "Epoch 39/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0092 - accuracy: 0.9975\n",
            "Epoch 40/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0040 - accuracy: 0.9988\n",
            "Epoch 41/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0071 - accuracy: 0.9977\n",
            "Epoch 42/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0070 - accuracy: 0.9982\n",
            "Epoch 43/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0070 - accuracy: 0.9982\n",
            "Epoch 44/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0047 - accuracy: 0.9986\n",
            "Epoch 45/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0062 - accuracy: 0.9980\n",
            "Epoch 46/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0043 - accuracy: 0.9987\n",
            "Epoch 47/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0062 - accuracy: 0.9982\n",
            "Epoch 48/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0038 - accuracy: 0.9989\n",
            "Epoch 49/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0052 - accuracy: 0.9984\n",
            "Epoch 50/50\n",
            "938/938 [==============================] - 2s 2ms/step - loss: 0.0075 - accuracy: 0.9981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa300183710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl08a3OUCi7w"
      },
      "source": [
        "**Loss And Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZy9uPbwyL_Q",
        "outputId": "2d8ec15a-dfd7-4f7a-8bef-6a603eb5ee47"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1345 - accuracy: 0.9813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.134455606341362, 0.9812999963760376]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcMzLkVpDH4D"
      },
      "source": [
        "**Nice, But Not Good Enough Yet.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x1gE0AxCuG5"
      },
      "source": [
        "# Fitting / Training - Now **With** The Necessary Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTAYuccXzB9H",
        "outputId": "6e38f961-54c9-4085-9f1e-0cb1df7a8686"
      },
      "source": [
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 20,\n",
        "    batch_size = 128,\n",
        "    validation_split = 0.15\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 8.7157e-04 - accuracy: 0.9996 - val_loss: 3.5849e-04 - val_accuracy: 0.9998\n",
            "Epoch 2/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 7.6337e-05 - accuracy: 1.0000 - val_loss: 2.3202e-04 - val_accuracy: 0.9999\n",
            "Epoch 3/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 2.6980e-05 - accuracy: 1.0000 - val_loss: 1.9614e-04 - val_accuracy: 0.9999\n",
            "Epoch 4/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 2.0302e-05 - accuracy: 1.0000 - val_loss: 1.7564e-04 - val_accuracy: 0.9999\n",
            "Epoch 5/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 1.6367e-05 - accuracy: 1.0000 - val_loss: 1.5763e-04 - val_accuracy: 0.9999\n",
            "Epoch 6/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 1.3456e-05 - accuracy: 1.0000 - val_loss: 1.4534e-04 - val_accuracy: 0.9999\n",
            "Epoch 7/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 1.1166e-05 - accuracy: 1.0000 - val_loss: 1.3504e-04 - val_accuracy: 0.9999\n",
            "Epoch 8/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 9.2812e-06 - accuracy: 1.0000 - val_loss: 1.2524e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 7.7115e-06 - accuracy: 1.0000 - val_loss: 1.1714e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 6.4007e-06 - accuracy: 1.0000 - val_loss: 1.0916e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 5.3141e-06 - accuracy: 1.0000 - val_loss: 1.0301e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 4.3982e-06 - accuracy: 1.0000 - val_loss: 9.7569e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 3.6416e-06 - accuracy: 1.0000 - val_loss: 9.2009e-05 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 2.9977e-06 - accuracy: 1.0000 - val_loss: 8.8344e-05 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 2.4724e-06 - accuracy: 1.0000 - val_loss: 8.3959e-05 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 2.0361e-06 - accuracy: 1.0000 - val_loss: 8.0973e-05 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 1.6705e-06 - accuracy: 1.0000 - val_loss: 7.7845e-05 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 1.3682e-06 - accuracy: 1.0000 - val_loss: 7.4584e-05 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 1.1145e-06 - accuracy: 1.0000 - val_loss: 7.3519e-05 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 9.1068e-07 - accuracy: 1.0000 - val_loss: 7.0914e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa2bc1c1ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcC9Lovxzzwv",
        "outputId": "a8f04f2f-4965-4db2-fa90-eda57b3acf8d"
      },
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 10,\n",
        "    batch_size = 128,\n",
        "    validation_split = 0.15\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 7.4102e-07 - accuracy: 1.0000 - val_loss: 6.8990e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 6.0429e-07 - accuracy: 1.0000 - val_loss: 6.6967e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 4.9187e-07 - accuracy: 1.0000 - val_loss: 6.5549e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 4.0036e-07 - accuracy: 1.0000 - val_loss: 6.3961e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 3.2527e-07 - accuracy: 1.0000 - val_loss: 6.2728e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 2.6467e-07 - accuracy: 1.0000 - val_loss: 6.1049e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 2.1481e-07 - accuracy: 1.0000 - val_loss: 5.8613e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 1.7440e-07 - accuracy: 1.0000 - val_loss: 5.5914e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 1.4125e-07 - accuracy: 1.0000 - val_loss: 5.4415e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 1.1465e-07 - accuracy: 1.0000 - val_loss: 5.3362e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "tUTy3cQD0lBI",
        "outputId": "e0f3d557-887e-43a5-9c34-306fd8b6a62b"
      },
      "source": [
        "df = pd.DataFrame(history.history)\n",
        "df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.410188e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.042898e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.918714e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.003556e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.252651e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.646745e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.148095e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.743988e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.412547e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.146458e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           loss  accuracy  val_loss  val_accuracy\n",
              "0  7.410188e-07       1.0  0.000069           1.0\n",
              "1  6.042898e-07       1.0  0.000067           1.0\n",
              "2  4.918714e-07       1.0  0.000066           1.0\n",
              "3  4.003556e-07       1.0  0.000064           1.0\n",
              "4  3.252651e-07       1.0  0.000063           1.0\n",
              "5  2.646745e-07       1.0  0.000061           1.0\n",
              "6  2.148095e-07       1.0  0.000059           1.0\n",
              "7  1.743988e-07       1.0  0.000056           1.0\n",
              "8  1.412547e-07       1.0  0.000054           1.0\n",
              "9  1.146458e-07       1.0  0.000053           1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "88uQiK8T0yiv",
        "outputId": "42fe1200-c8d6-4f1f-a431-36bba0cb8733"
      },
      "source": [
        "df.plot(y = 'val_accuracy')\n",
        "df.plot(y = 'val_loss')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa2aa7efe90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASRElEQVR4nO3df6zddZ3n8ecLerEOv20rP9quZTOwUCgI3AEc4pTAMgGXoRmTWhtXRxJDzCCMsGaDYqTDDycRXNEMqSKLWkUa7MgGWXbxByXEOBBvB+RHu7AddrW3IL2UUu0abIH3/nFP621t771tTznth+cjuck53x/nvO8X+rzf+z3n3puqQpLUrv16PYAkac8y9JLUOEMvSY0z9JLUOEMvSY2b0OsBtjV58uSaMWNGr8eQpH3KsmXLXqqqKdtbt9eFfsaMGQwMDPR6DEnapyT55Y7WeelGkhpn6CWpcYZekhq3112jl7R32bRpE4ODg7z66qu9HkXAxIkTmTZtGn19fePex9BLGtXg4CAHH3wwM2bMIEmvx3lLqyrWrl3L4OAgxxxzzLj389KNpFG9+uqrTJo0ycjvBZIwadKknf7uytBLGpOR33vsyn8LQy9JjTP0ktQ4Qy+pOQcddFCvR9irGHpJ2kNee+21Xo8A+PZKSTvh73/wNMuf/01XH3Pm0Ydw7V+dOOo2V199NdOnT+eyyy4DYMGCBUyYMIGlS5eybt06Nm3axA033MCcOXPGfL4NGzYwZ86c7e63aNEibr75ZpJw8skn8+1vf5sXX3yRj3/84zz33HMALFy4kKOPPpqLLrqIp556CoCbb76ZDRs2sGDBAs455xze/e5389Of/pT58+dz3HHHccMNN7Bx40YmTZrEnXfeyRFHHMGGDRu4/PLLGRgYIAnXXnst69ev54knnuCWW24B4Otf/zrLly/nS1/60i4fXzD0kvYB8+bN45Of/OSW0N9999088MADXHHFFRxyyCG89NJLnHXWWVx88cVjvitl4sSJ3HPPPX+03/Lly7nhhhv42c9+xuTJk3n55ZcBuOKKK5g9ezb33HMPr7/+Ohs2bGDdunWjPsfGjRu3/HLGdevW8cgjj5CE22+/nS984Qt88Ytf5Prrr+fQQw/lySef3LJdX18fN954IzfddBN9fX184xvf4Gtf+9ruHj5DL2n8xjrz3lNOPfVU1qxZw/PPP8/Q0BCHH344Rx55JFdeeSUPP/ww++23H6tXr+bFF1/kyCOPHPWxqorPfOYzf7Tfgw8+yNy5c5k8eTIA73jHOwB48MEHWbRoEQD7778/hx566Jihnzdv3pbbg4ODzJs3jxdeeIGNGzdu+UGnH//4xyxevHjLdocffjgA5557Lvfddx8nnHACmzZtYtasWTt5tP6YoZe0T5g7dy5Llizh17/+NfPmzePOO+9kaGiIZcuW0dfXx4wZM8b1g0S7ut9IEyZM4I033thyf9v9DzzwwC23L7/8cq666iouvvhiHnroIRYsWDDqY3/sYx/j85//PMcffzyXXHLJTs21I74YK2mfMG/ePBYvXsySJUuYO3cu69ev553vfCd9fX0sXbqUX/5yh7+OfSs72u/cc8/le9/7HmvXrgXYcunmvPPOY+HChQC8/vrrrF+/niOOOII1a9awdu1afv/733PfffeN+nxTp04F4Fvf+taW5eeffz633nrrlvubv0s488wzWbVqFd/97neZP3/+eA/PqAy9pH3CiSeeyG9/+1umTp3KUUcdxYc+9CEGBgaYNWsWixYt4vjjjx/X4+xovxNPPJFrrrmG2bNnc8opp3DVVVcB8OUvf5mlS5cya9YsTj/9dJYvX05fXx+f+9znOOOMMzj//PNHfe4FCxYwd+5cTj/99C2XhQA++9nPsm7dOk466SROOeUUli5dumXdBz7wAc4+++wtl3N2V6qqKw/ULf39/eVfmJL2HitWrOCEE07o9RhvKRdddBFXXnkl55133nbXb++/SZJlVdW/ve09o5ekvcQrr7zCcccdx9vf/vYdRn5X+GKspCY9+eSTfPjDH95q2dve9jYeffTRHk00tsMOO4xnn322649r6CWNqar2ud9gOWvWLB5//PFej9F1u3K53Us3kkY1ceJE1q5du0uBUXdt/sMjEydO3Kn9PKOXNKpp06YxODjI0NBQr0cRf/hTgjvD0EsaVV9f30792Trtfbx0I0mNGzP0Se5IsibJUztYnyRfSbIyyRNJTttm/SFJBpP8Y7eGliSN33jO6L8JXDDK+guBYzsflwILt1l/PfDwrgwnSdp9Y4a+qh4GXh5lkznAohr2CHBYkqMAkpwOHAH8sBvDSpJ2Xjeu0U8FVo24PwhMTbIf8EXgU2M9QJJLkwwkGfCVfUnqrj35YuzfAvdX1eBYG1bVbVXVX1X9U6ZM2YMjSdJbTzfeXrkamD7i/rTOsvcA703yt8BBwAFJNlTV1V14TknSOHUj9PcCn0iyGDgTWF9VLwAf2rxBko8C/UZekt58Y4Y+yV3AOcDkJIPAtUAfQFV9FbgfeB+wEvgd0J0/iSJJ6ooxQ19Vo/6Jkxr+BRiXjbHNNxl+m6Yk6U3mT8ZKUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1bszQJ7kjyZokT+1gfZJ8JcnKJE8kOa2z/N1J/jnJ053l87o9vCRpbOM5o/8mcMEo6y8Eju18XAos7Cz/HfCRqjqxs/8tSQ7b9VElSbtiwlgbVNXDSWaMsskcYFFVFfBIksOSHFVVz454jOeTrAGmAK/s5sySpJ3QjWv0U4FVI+4PdpZtkeQM4ADgX7vwfJKknbDHX4xNchTwbeCSqnpjB9tcmmQgycDQ0NCeHkmS3lK6EfrVwPQR96d1lpHkEOC/A9dU1SM7eoCquq2q+quqf8qUKV0YSZK0WTdCfy/wkc67b84C1lfVC0kOAO5h+Pr9ki48jyRpF4z5YmySu4BzgMlJBoFrgT6AqvoqcD/wPmAlw++0uaSz6weAvwAmJfloZ9lHq+rxLs4vSRrDeN51M3+M9QVctp3l3wG+s+ujSZK6wZ+MlaTGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGGXpJapyhl6TGjRn6JHckWZPkqR2sT5KvJFmZ5Ikkp41Y9zdJ/nfn42+6ObgkaXzGc0b/TeCCUdZfCBzb+bgUWAiQ5B3AtcCZwBnAtUkO351hJUk7b8JYG1TVw0lmjLLJHGBRVRXwSJLDkhwFnAP8qKpeBkjyI4a/YNy1u0PvyN//4GmWP/+bPfXwkrRHzTz6EK79qxO7/rjduEY/FVg14v5gZ9mOlv+RJJcmGUgyMDQ01IWRJEmbjXlG/2aoqtuA2wD6+/trVx9nT3wllKR9XTfO6FcD00fcn9ZZtqPlkqQ3UTdCfy/wkc67b84C1lfVC8ADwF8mObzzIuxfdpZJkt5EY166SXIXwy+sTk4yyPA7afoAquqrwP3A+4CVwO+ASzrrXk5yPfDzzkNdt/mFWUnSm2c877qZP8b6Ai7bwbo7gDt2bTRJUjf4k7GS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNG1fok1yQ5JkkK5NcvZ3170rykyRPJHkoybQR676Q5OkkK5J8JUm6+QlIkkY3ZuiT7A/cClwIzATmJ5m5zWY3A4uq6mTgOuAfOvv+OXA2cDJwEvBnwOyuTS9JGtN4zujPAFZW1XNVtRFYDMzZZpuZwIOd20tHrC9gInAA8DagD3hxd4eWJI3feEI/FVg14v5gZ9lIvwDe37n918DBSSZV1T8zHP4XOh8PVNWK3RtZkrQzuvVi7KeA2UkeY/jSzGrg9SR/CpwATGP4i8O5Sd677c5JLk0ykGRgaGioSyNJkmB8oV8NTB9xf1pn2RZV9XxVvb+qTgWu6Sx7heGz+0eqakNVbQD+B/CebZ+gqm6rqv6q6p8yZcoufiqSpO0ZT+h/Dhyb5JgkBwAfBO4duUGSyUk2P9angTs6t3/F8Jn+hCR9DJ/te+lGkt5EY4a+ql4DPgE8wHCk766qp5Ncl+TizmbnAM8keRY4Arixs3wJ8K/Akwxfx/9FVf2gu5+CJGk0qapez7CV/v7+GhgY6PUYkrRPSbKsqvq3t86fjJWkxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxhl6SWqcoZekxo0r9EkuSPJMkpVJrt7O+ncl+UmSJ5I8lGTaiHX/JskPk6xIsjzJjO6NL0kay5ihT7I/cCtwITATmJ9k5jab3QwsqqqTgeuAfxixbhFwU1WdAJwBrOnG4JKk8RnPGf0ZwMqqeq6qNgKLgTnbbDMTeLBze+nm9Z0vCBOq6kcAVbWhqn7XlcklSeMyntBPBVaNuD/YWTbSL4D3d27/NXBwkknAccArSb6f5LEkN3W+Q9hKkkuTDCQZGBoa2vnPQpK0Q916MfZTwOwkjwGzgdXA68AE4L2d9X8G/Fvgo9vuXFW3VVV/VfVPmTKlSyNJkmB8oV8NTB9xf1pn2RZV9XxVvb+qTgWu6Sx7heGz/8c7l31eA/4bcFpXJpckjct4Qv9z4NgkxyQ5APggcO/IDZJMTrL5sT4N3DFi38OSbD5NPxdYvvtjS5LGa8zQd87EPwE8AKwA7q6qp5Ncl+TizmbnAM8keRY4Arixs+/rDF+2+UmSJ4EAX+/6ZyFJ2qFUVa9n2Ep/f38NDAz0egxJ2qckWVZV/dtb50/GSlLjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNS5V1esZtpJkCPjlbjzEZOClLo2zr/NYbM3jsTWPxx+0cCzeVVVTtrdirwv97koyUFX9vZ5jb+Cx2JrHY2sejz9o/Vh46UaSGmfoJalxLYb+tl4PsBfxWGzN47E1j8cfNH0smrtGL0naWotn9JKkEQy9JDWumdAnuSDJM0lWJrm61/P0UpLpSZYmWZ7k6SR/1+uZei3J/kkeS3Jfr2fptSSHJVmS5H8lWZHkPb2eqZeSXNn5d/JUkruSTOz1TN3WROiT7A/cClwIzATmJ5nZ26l66jXgP1XVTOAs4LK3+PEA+DtgRa+H2Et8GfifVXU8cApv4eOSZCpwBdBfVScB+wMf7O1U3ddE6IEzgJVV9VxVbQQWA3N6PFPPVNULVfUvndu/Zfgf8tTeTtU7SaYB/wG4vdez9FqSQ4G/AP4rQFVtrKpXejtVz00A3p5kAvAnwPM9nqfrWgn9VGDViPuDvIXDNlKSGcCpwKO9naSnbgH+M/BGrwfZCxwDDAHf6FzKuj3Jgb0eqleqajVwM/Ar4AVgfVX9sLdTdV8rodd2JDkI+Cfgk1X1m17P0wtJLgLWVNWyXs+yl5gAnAYsrKpTgf8HvGVf00pyOMPf/R8DHA0cmOQ/9naq7msl9KuB6SPuT+sse8tK0sdw5O+squ/3ep4eOhu4OMn/ZfiS3rlJvtPbkXpqEBisqs3f4S1hOPxvVf8e+D9VNVRVm4DvA3/e45m6rpXQ/xw4NskxSQ5g+MWUe3s8U88kCcPXYFdU1X/p9Ty9VFWfrqppVTWD4f8vHqyq5s7Yxquqfg2sSvLvOovOA5b3cKRe+xVwVpI/6fy7OY8GX5ye0OsBuqGqXkvyCeABhl81v6Oqnu7xWL10NvBh4Mkkj3eWfaaq7u/hTNp7XA7c2Tkpeg64pMfz9ExVPZpkCfAvDL9b7TEa/HUI/goESWpcK5duJEk7YOglqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIa9/8Bl77vkRFequkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyDiC1yg1MfT"
      },
      "source": [
        "y = model.predict(x_test[0:1])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RMMO-1V3ECP",
        "outputId": "37008077-f3d6-4eb9-c66c-31a72c3a5d3a"
      },
      "source": [
        "y"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.9421073e-26, 7.0085466e-26, 2.4435277e-25, 1.2551065e-19,\n",
              "        5.6638527e-22, 2.6037214e-26, 1.7012615e-34, 1.0000000e+00,\n",
              "        5.4625636e-22, 6.2625736e-22]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONOAuzvs3JGd",
        "outputId": "acfb96a3-d763-4a48-d5ba-024dd7734dc4"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNWjHOXc1kWR",
        "outputId": "d776b619-a0a4-48d2-f64b-1c3d5b3d2980"
      },
      "source": [
        "tf.argmax(y, axis=-1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([7])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "99jxaDUW1l5v",
        "outputId": "e23a57f9-e4d9-4a3c-ca0e-887b076053e8"
      },
      "source": [
        "plt.imshow(x_test[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa2aa5c4290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANiklEQVR4nO3df4wc9XnH8c8n/kV8QGtDcF3j4ISQqE4aSHWBRNDKESUFImSiJBRLtVyJ5lALElRRW0QVBalVSlEIok0aySluHESgaQBhJTSNa6W1UKljg4yxgdaEmsau8QFOaxPAP/DTP24cHXD7vWNndmft5/2SVrs7z87Oo/F9PLMzO/t1RAjA8e9tbTcAoD8IO5AEYQeSIOxAEoQdSGJ6Pxc207PiBA31c5FAKq/qZzoYBzxRrVbYbV8s6XZJ0yT9bUTcXHr9CRrSeb6wziIBFGyIdR1rXe/G254m6auSLpG0WNIy24u7fT8AvVXnM/u5kp6OiGci4qCkeyQtbaYtAE2rE/YFkn4y7vnOatrr2B6xvcn2pkM6UGNxAOro+dH4iFgZEcMRMTxDs3q9OAAd1An7LkkLxz0/vZoGYADVCftGSWfZfpftmZKulLSmmbYANK3rU28Rcdj2tZL+SWOn3lZFxLbGOgPQqFrn2SPiQUkPNtQLgB7i67JAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJGoN2Wx7h6T9kl6TdDgihptoCkDzaoW98rGIeKGB9wHQQ+zGA0nUDXtI+oHtR2yPTPQC2yO2N9nedEgHai4OQLfq7sZfEBG7bJ8maa3tpyJi/fgXRMRKSSsl6WTPjZrLA9ClWlv2iNhV3Y9Kul/SuU00BaB5XYfd9pDtk44+lvRxSVubagxAs+rsxs+TdL/to+/zrYj4fiNdAWhc12GPiGcknd1gLwB6iFNvQBKEHUiCsANJEHYgCcIOJNHEhTApvPjZj3asvXP508V5nxqdV6wfPDCjWF9wd7k+e+dLHWtHNj9RnBd5sGUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4zz5Ff/xH3+pY+9TQT8szn1lz4UvK5R2HX+5Yu/35j9Vc+LHrR6NndKwN3foLxXmnr3uk6XZax5YdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JwRP8GaTnZc+M8X9i35TXpZ58+r2PthQ+W/8+c82R5Hf/0V1ysz/zg/xbrt3zgvo61i97+SnHe7718YrH+idmdr5Wv65U4WKxvODBUrC854VDXy37P964u1t87srHr927ThlinfbF3wj8otuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATXs0/R0Hc2FGr13vvkerPrr39pScfan5+/qLzsfy3/5v0tS97TRUdTM/2VI8X60Jbdxfop6+8t1n91Zuff25+9o/xb/MejSbfstlfZHrW9ddy0ubbX2t5e3c/pbZsA6prKbvw3JF38hmk3SFoXEWdJWlc9BzDAJg17RKyXtPcNk5dKWl09Xi3p8ob7AtCwbj+zz4uIox+onpPUcTAz2yOSRiTpBM3ucnEA6qp9ND7GrqTpeKVHRKyMiOGIGJ6hWXUXB6BL3YZ9j+35klTdjzbXEoBe6DbsayStqB6vkPRAM+0A6JVJP7Pbvltjv1x+qu2dkr4g6WZJ37Z9laRnJV3RyyZRdvi5PR1rQ/d2rknSa5O899B3Xuyio2bs+b2PFuvvn1n+8/3S3vd1rC36u2eK8x4uVo9Nk4Y9IpZ1KB2bv0IBJMXXZYEkCDuQBGEHkiDsQBKEHUiCS1zRmulnLCzWv3LjV4r1GZ5WrP/D7b/ZsXbK7oeL8x6P2LIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKcZ0drnvrDBcX6h2eVh7LedrA8HPXcJ15+yz0dz9iyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASnGdHTx34xIc71h799G2TzF0eQej3r7uuWH/7v/1okvfPhS07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBeXb01H9f0nl7cqLL59GX/ddFxfrs7z9WrEexms+kW3bbq2yP2t46btpNtnfZ3lzdLu1tmwDqmspu/DckXTzB9Nsi4pzq9mCzbQFo2qRhj4j1kvb2oRcAPVTnAN21trdUu/lzOr3I9ojtTbY3HdKBGosDUEe3Yf+apDMlnSNpt6RbO70wIlZGxHBEDM+Y5MIGAL3TVdgjYk9EvBYRRyR9XdK5zbYFoGldhd32/HFPPylpa6fXAhgMk55nt323pCWSTrW9U9IXJC2xfY7GTmXukHR1D3vEAHvbSScV68t//aGOtX1HXi3OO/rFdxfrsw5sLNbxepOGPSKWTTD5jh70AqCH+LoskARhB5Ig7EAShB1IgrADSXCJK2rZftP7i/Xvnvo3HWtLt3+qOO+sBzm11iS27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOfZUfR/v/ORYn3Lb/9Vsf7jw4c61l76y9OL887S7mIdbw1bdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgvPsyU1f8MvF+vWf//tifZbLf0JXPra8Y+0d/8j16v3Elh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuA8+3HO08v/xGd/d2ex/pkTXyzW79p/WrE+7/OdtydHinOiaZNu2W0vtP1D20/Y3mb7umr6XNtrbW+v7uf0vl0A3ZrKbvxhSZ+LiMWSPiLpGtuLJd0gaV1EnCVpXfUcwICaNOwRsTsiHq0e75f0pKQFkpZKWl29bLWky3vVJID63tJndtuLJH1I0gZJ8yLi6I+EPSdpXod5RiSNSNIJmt1tnwBqmvLReNsnSrpX0vURsW98LSJCUkw0X0SsjIjhiBieoVm1mgXQvSmF3fYMjQX9roi4r5q8x/b8qj5f0mhvWgTQhEl3421b0h2SnoyIL48rrZG0QtLN1f0DPekQ9Zz9vmL5z067s9bbf/WLnynWf/Gxh2u9P5ozlc/s50taLulx25uraTdqLOTftn2VpGclXdGbFgE0YdKwR8RDktyhfGGz7QDoFb4uCyRB2IEkCDuQBGEHkiDsQBJc4nocmLb4vR1rI/fU+/rD4lXXFOuL7vz3Wu+P/mHLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJ79OPDUH3T+Yd/LZu/rWJuK0//lYPkFMeEPFGEAsWUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4z34MePWyc4v1dZfdWqgy5BbGsGUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSSmMj77QknflDRPUkhaGRG3275J0mclPV+99MaIeLBXjWb2P+dPK9bfOb37c+l37T+tWJ+xr3w9O1ezHzum8qWaw5I+FxGP2j5J0iO211a12yLiS71rD0BTpjI++25Ju6vH+20/KWlBrxsD0Ky39Jnd9iJJH5K0oZp0re0ttlfZnvC3kWyP2N5ke9MhHajVLIDuTTnstk+UdK+k6yNin6SvSTpT0jka2/JP+AXtiFgZEcMRMTxDsxpoGUA3phR22zM0FvS7IuI+SYqIPRHxWkQckfR1SeWrNQC0atKw27akOyQ9GRFfHjd9/riXfVLS1ubbA9CUqRyNP1/SckmP295cTbtR0jLb52js7MsOSVf3pEPU8hcvLi7WH/6tRcV67H68wW7QpqkcjX9IkicocU4dOIbwDTogCcIOJEHYgSQIO5AEYQeSIOxAEo4+Drl7sufGeb6wb8sDstkQ67Qv9k50qpwtO5AFYQeSIOxAEoQdSIKwA0kQdiAJwg4k0dfz7Lafl/TsuEmnSnqhbw28NYPa26D2JdFbt5rs7YyIeMdEhb6G/U0LtzdFxHBrDRQMam+D2pdEb93qV2/sxgNJEHYgibbDvrLl5ZcMam+D2pdEb93qS2+tfmYH0D9tb9kB9AlhB5JoJey2L7b9H7aftn1DGz10YnuH7cdtb7a9qeVeVtketb113LS5ttfa3l7dTzjGXku93WR7V7XuNtu+tKXeFtr+oe0nbG+zfV01vdV1V+irL+ut75/ZbU+T9J+SLpK0U9JGScsi4om+NtKB7R2ShiOi9S9g2P4NSS9J+mZEfKCadoukvRFxc/Uf5ZyI+JMB6e0mSS+1PYx3NVrR/PHDjEu6XNLvqsV1V+jrCvVhvbWxZT9X0tMR8UxEHJR0j6SlLfQx8CJivaS9b5i8VNLq6vFqjf2x9F2H3gZCROyOiEerx/slHR1mvNV1V+irL9oI+wJJPxn3fKcGa7z3kPQD24/YHmm7mQnMi4jd1ePnJM1rs5kJTDqMdz+9YZjxgVl33Qx/XhcH6N7sgoj4NUmXSLqm2l0dSDH2GWyQzp1OaRjvfplgmPGfa3PddTv8eV1thH2XpIXjnp9eTRsIEbGruh+VdL8GbyjqPUdH0K3uR1vu5+cGaRjviYYZ1wCsuzaHP28j7BslnWX7XbZnSrpS0poW+ngT20PVgRPZHpL0cQ3eUNRrJK2oHq+Q9ECLvbzOoAzj3WmYcbW87lof/jwi+n6TdKnGjsj/WNKfttFDh77eLemx6rat7d4k3a2x3bpDGju2cZWkUyStk7Rd0j9LmjtAvd0p6XFJWzQWrPkt9XaBxnbRt0jaXN0ubXvdFfrqy3rj67JAEhygA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk/h9BCfQTVPflJQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Gy0h1ytb6A"
      },
      "source": [
        "# Now With CallBacks: Callbacks Prevent The System From \"Overlearning\" Which Leads To Worse Results And An Excess Of Computing Ressources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3bLYmrRtj8m",
        "outputId": "686b475b-1d24-48eb-f3d5-92765ce63e13"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 30,\n",
        "    batch_size = 128,\n",
        "    validation_split = .15,\n",
        "    callbacks = [EarlyStopping(patience= 3)]\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 9.2691e-08 - accuracy: 1.0000 - val_loss: 5.2609e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 7.5361e-08 - accuracy: 1.0000 - val_loss: 5.0924e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 6.1355e-08 - accuracy: 1.0000 - val_loss: 5.1027e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 4.9839e-08 - accuracy: 1.0000 - val_loss: 5.0661e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 4.0592e-08 - accuracy: 1.0000 - val_loss: 5.1561e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 3.3107e-08 - accuracy: 1.0000 - val_loss: 5.1727e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 2.7077e-08 - accuracy: 1.0000 - val_loss: 5.1999e-05 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa2aa609310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHYcZGnMEtKz"
      },
      "source": [
        "**The System Stopped \"Learning\" After The Results Didn't Grow Better For 3 Epochs (\"Patience = 3\")**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRvp6QxYtkMn"
      },
      "source": [
        "#callbacks = [tf.keras.callbacks.EarlyStopping()]  patience \n",
        "# Arguments: 1) patience = 0 (def), 2) monitor = 'val_loss' (default) 3) min_delta = 0.01 (measure of improvement), 4) mode = 'auto'. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yMwrztIFP9j"
      },
      "source": [
        "# ModelCheckpoint Returns To The Kept Best Result After A Defined Number Of \"Patiences\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INczJKgsuV9g",
        "outputId": "826fd787-c394-4076-cbd7-c650532d2666"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "path = 'hamdwriting/model_weights'\n",
        "checkpoint = ModelCheckpoint(filepath = path,\n",
        "                             frequency = 'epoch',\n",
        "                             save_weights_only = True,\n",
        "                             save_best_only = True,\n",
        "                             verbose =1\n",
        "                          )\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 15,\n",
        "    batch_size = 128,\n",
        "    validation_split = .15,\n",
        "    callbacks = [EarlyStopping(patience= 2), checkpoint]\n",
        "\n",
        "\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 2.2192e-08 - accuracy: 1.0000 - val_loss: 5.1972e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00005, saving model to hamdwriting/model_weights\n",
            "Epoch 2/15\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 1.8185e-08 - accuracy: 1.0000 - val_loss: 5.2414e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.00005\n",
            "Epoch 3/15\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 1.4927e-08 - accuracy: 1.0000 - val_loss: 4.9971e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.00005 to 0.00005, saving model to hamdwriting/model_weights\n",
            "Epoch 4/15\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 1.2332e-08 - accuracy: 1.0000 - val_loss: 5.0807e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.00005\n",
            "Epoch 5/15\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 1.0226e-08 - accuracy: 1.0000 - val_loss: 5.0921e-05 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.00005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa2aa511090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9Krb7KPFn-D"
      },
      "source": [
        "**The 3rd Epoch Brought The Best Results With The val_loss < 5. With patience = 2 The Computing Was Stopped After The 5th Epoch.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n22slxQ_uWA0",
        "outputId": "fb6eabde-98c8-48b1-a75c-757540f529e7"
      },
      "source": [
        "! ls hamdwriting"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint  model_weights.data-00000-of-00001  model_weights.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibt2DjCkD8Kn",
        "outputId": "38f83a1e-981c-4242-9186-eebf438223f5"
      },
      "source": [
        "! model_weights.data-00000-of-00001"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: model_weights.data-00000-of-00001: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFvP74eZuWEh",
        "outputId": "3515f39d-5542-4ab4-de61-a1fbab168260"
      },
      "source": [
        "model.load_weights(path)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa2aa4c6110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBuEVrCSDqKs"
      },
      "source": [
        "# Already Saved Model In Tensorflow: Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_FayM-uwVSc"
      },
      "source": [
        "from tensorflow.keras.applications import InceptionV3"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJxtYXd87QFt",
        "outputId": "69fee8c6-65cf-4355-f701-176c801eee48"
      },
      "source": [
        "model = InceptionV3()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1CpMbLP7UMm",
        "outputId": "9dcf9819-1629-4a79-d1f5-71c51fd673b8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,851,784\n",
            "Trainable params: 23,817,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCadepp57XHa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}