{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hand_Writing_recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_hzfVFMmU2E"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyV7Pipqt2mp"
      },
      "source": [
        "# mnist dataset : https://keras.io/api/datasets/mnist/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j6DWnMTtFv4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5elUylJmaJf",
        "outputId": "693f4625-15dd-42cc-c0ae-6d2fbf4fb793"
      },
      "source": [
        "(x_train, y_train) ,(x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "pThJv4NosXh7",
        "outputId": "ae653613-e713-42e7-a25f-3a8490cd3fe2"
      },
      "source": [
        "plt.imshow(x_train[7]) # 28 X 28 images"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f95c389e750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1j5XolusaPt",
        "outputId": "a90074a7-814c-421b-b881-2536ef6d4e85"
      },
      "source": [
        "y_train[7]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOkpkAJsx8rP"
      },
      "source": [
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iR8Y245zqWH"
      },
      "source": [
        "#x_train[0]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_EIQaSnzDLA"
      },
      "source": [
        "## Flatten: Used to convert N-D array to 1D -arrays\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WASzwylEujqO"
      },
      "source": [
        "model = models.Sequential(\n",
        "    [\n",
        "    layers.Flatten(input_shape = (28,28)),\n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    #layers.Dropout(0.2),\n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    #layers.Dropout(0.2),\n",
        "    layers.Dense(10, activation = 'softmax' )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Dropout, optimizer, sparse_categorical_crossentropy\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam', \n",
        "    loss = 'sparse_categorical_crossentropy',  # binary_crossentropy, categorical_crossentropy\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yt5uoK5yZeT",
        "outputId": "26df921e-a02c-46b6-ec5b-f0cc4c7fe8fb"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxV4SgU1xDXq",
        "outputId": "07671689-07bd-4949-bb62-af9722eedc15"
      },
      "source": [
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 50,\n",
        "    batch_size = 128\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5861 - accuracy: 0.8432\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.1395 - accuracy: 0.9576\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0873 - accuracy: 0.9732\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0637 - accuracy: 0.9808\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0516 - accuracy: 0.9842\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0375 - accuracy: 0.9888\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0318 - accuracy: 0.9901\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9920\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0201 - accuracy: 0.9936\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0180 - accuracy: 0.9945\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0145 - accuracy: 0.9957\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0120 - accuracy: 0.9962\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0108 - accuracy: 0.9966\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0105 - accuracy: 0.9967\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0093 - accuracy: 0.9972\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0118 - accuracy: 0.9959\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0072 - accuracy: 0.9977\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9982\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0064 - accuracy: 0.9980\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0098 - accuracy: 0.9965\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0076 - accuracy: 0.9973\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9986\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0123 - accuracy: 0.9964\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9984\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0015 - accuracy: 0.9997\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0020 - accuracy: 0.9994\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0115 - accuracy: 0.9963\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9979\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 0.9987\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9982\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9977\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9985\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0073 - accuracy: 0.9976\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 0.9989\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9983\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 3.1339e-04 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9986\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9980\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 0.9990\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 0.9988\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9989\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 0.9987\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9984\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0056 - accuracy: 0.9983\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 0.9997\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.2474e-04 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 3.1953e-05 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.2467e-05 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f95b017ae10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZy9uPbwyL_Q",
        "outputId": "611e3c3c-3068-40d3-e0a0-1804322b2d83"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1256 - accuracy: 0.9818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12557299435138702, 0.9818000197410583]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTAYuccXzB9H",
        "outputId": "d8963191-11d8-4cec-8aec-490f02666935"
      },
      "source": [
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 10,\n",
        "    batch_size = 128,\n",
        "    validation_split = 0.15\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.6308 - accuracy: 0.8189 - val_loss: 0.1497 - val_accuracy: 0.9561\n",
            "Epoch 2/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.1486 - accuracy: 0.9570 - val_loss: 0.1079 - val_accuracy: 0.9686\n",
            "Epoch 3/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9710 - val_loss: 0.0930 - val_accuracy: 0.9708\n",
            "Epoch 4/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0664 - accuracy: 0.9807 - val_loss: 0.0866 - val_accuracy: 0.9728\n",
            "Epoch 5/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0525 - accuracy: 0.9841 - val_loss: 0.0950 - val_accuracy: 0.9718\n",
            "Epoch 6/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 0.0908 - val_accuracy: 0.9756\n",
            "Epoch 7/10\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0331 - accuracy: 0.9902 - val_loss: 0.0797 - val_accuracy: 0.9764\n",
            "Epoch 8/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 0.0850 - val_accuracy: 0.9749\n",
            "Epoch 9/10\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.0850 - val_accuracy: 0.9767\n",
            "Epoch 10/10\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.0812 - val_accuracy: 0.9790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f957616e190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcC9Lovxzzwv",
        "outputId": "03c02c93-b247-4a2f-ca37-02a8e10e471f"
      },
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 7,\n",
        "    batch_size = 128,\n",
        "    validation_split = 0.15\n",
        ")\n",
        "\n",
        "# in Machine Learning: train - test\n",
        "# in deep learning: train - validation - test"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.6376 - accuracy: 0.8180 - val_loss: 0.1678 - val_accuracy: 0.9514\n",
            "Epoch 2/7\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.1490 - accuracy: 0.9560 - val_loss: 0.1073 - val_accuracy: 0.9688\n",
            "Epoch 3/7\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9718 - val_loss: 0.0900 - val_accuracy: 0.9736\n",
            "Epoch 4/7\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0679 - accuracy: 0.9797 - val_loss: 0.0871 - val_accuracy: 0.9749\n",
            "Epoch 5/7\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0502 - accuracy: 0.9850 - val_loss: 0.0765 - val_accuracy: 0.9772\n",
            "Epoch 6/7\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0371 - accuracy: 0.9892 - val_loss: 0.0819 - val_accuracy: 0.9769\n",
            "Epoch 7/7\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 0.0806 - val_accuracy: 0.9773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "tUTy3cQD0lBI",
        "outputId": "f8a46ce3-b874-4744-f871-95d5bffc9b8b"
      },
      "source": [
        "df = pd.DataFrame(history.history)\n",
        "df"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.347265</td>\n",
              "      <td>0.900784</td>\n",
              "      <td>0.167820</td>\n",
              "      <td>0.951444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.136086</td>\n",
              "      <td>0.959627</td>\n",
              "      <td>0.107330</td>\n",
              "      <td>0.968778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.093177</td>\n",
              "      <td>0.971373</td>\n",
              "      <td>0.090046</td>\n",
              "      <td>0.973556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.068610</td>\n",
              "      <td>0.978980</td>\n",
              "      <td>0.087053</td>\n",
              "      <td>0.974889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.051970</td>\n",
              "      <td>0.984294</td>\n",
              "      <td>0.076537</td>\n",
              "      <td>0.977222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.040198</td>\n",
              "      <td>0.987804</td>\n",
              "      <td>0.081894</td>\n",
              "      <td>0.976889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.032436</td>\n",
              "      <td>0.990137</td>\n",
              "      <td>0.080581</td>\n",
              "      <td>0.977333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy\n",
              "0  0.347265  0.900784  0.167820      0.951444\n",
              "1  0.136086  0.959627  0.107330      0.968778\n",
              "2  0.093177  0.971373  0.090046      0.973556\n",
              "3  0.068610  0.978980  0.087053      0.974889\n",
              "4  0.051970  0.984294  0.076537      0.977222\n",
              "5  0.040198  0.987804  0.081894      0.976889\n",
              "6  0.032436  0.990137  0.080581      0.977333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "88uQiK8T0yiv",
        "outputId": "5192e4a0-0bb0-431c-af39-1364453943f2"
      },
      "source": [
        "df.plot(y = 'val_accuracy')\n",
        "df.plot(y = 'val_loss')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f956278ac90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyDiC1yg1MfT"
      },
      "source": [
        "y = model.predict(x_test[0:1])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RMMO-1V3ECP",
        "outputId": "ae654f2d-cbe2-4855-922b-30303a0e547f"
      },
      "source": [
        "y"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.3147031e-08, 1.7291875e-07, 7.3216456e-06, 3.8334334e-04,\n",
              "        2.7177655e-10, 6.3254276e-08, 2.0839318e-12, 9.9960154e-01,\n",
              "        4.8004799e-06, 2.7260569e-06]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONOAuzvs3JGd",
        "outputId": "47ee84ba-d941-493e-881b-8c5df13afdc8"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNWjHOXc1kWR",
        "outputId": "bd0f4324-0ef2-4c99-a66d-12c11890caa4"
      },
      "source": [
        "tf.argmax(y, axis=-1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([7])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "99jxaDUW1l5v",
        "outputId": "697bf4bf-481c-410d-ffb0-7702c5acab50"
      },
      "source": [
        "plt.imshow(x_test[0])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f956267cbd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ToYF24c2Roz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Gy0h1ytb6A"
      },
      "source": [
        "# CallBAcks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO_YG1LYtgTH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G01pXXttjp8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3bLYmrRtj8m",
        "outputId": "1dc498f7-a3dd-4546-bf4b-6972f2be5a1d"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 30,\n",
        "    batch_size = 128,\n",
        "    validation_split = .15,\n",
        "    callbacks = [EarlyStopping(patience= 2)]\n",
        ")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.6330 - accuracy: 0.8174 - val_loss: 0.1478 - val_accuracy: 0.9589\n",
            "Epoch 2/30\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.1492 - accuracy: 0.9556 - val_loss: 0.1148 - val_accuracy: 0.9670\n",
            "Epoch 3/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9709 - val_loss: 0.0928 - val_accuracy: 0.9720\n",
            "Epoch 4/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0721 - accuracy: 0.9775 - val_loss: 0.0853 - val_accuracy: 0.9743\n",
            "Epoch 5/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0499 - accuracy: 0.9855 - val_loss: 0.0787 - val_accuracy: 0.9768\n",
            "Epoch 6/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0386 - accuracy: 0.9890 - val_loss: 0.0826 - val_accuracy: 0.9756\n",
            "Epoch 7/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9900 - val_loss: 0.0770 - val_accuracy: 0.9787\n",
            "Epoch 8/30\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 0.0823 - val_accuracy: 0.9780\n",
            "Epoch 9/30\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9938 - val_loss: 0.0955 - val_accuracy: 0.9756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f95625bd150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRvp6QxYtkMn"
      },
      "source": [
        "#callbacks = [tf.keras.callbacks.EarlyStopping()]  patience \n",
        "# Arguments: 1) patience = 0 (def), 2) monitor = 'val_loss' (default) 3) min_delta = 0.01 (measure of improvement), 4) mode = 'auto'. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INczJKgsuV9g",
        "outputId": "c421305a-7b93-483c-9cde-5c5dd0bfbf69"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "path = 'hamdwriting/model_weights'\n",
        "checkpoint = ModelCheckpoint(filepath = path,\n",
        "                             frequency = 'epoch',\n",
        "                             save_weights_only = True,\n",
        "                             save_best_only = True,\n",
        "                             verbose =1\n",
        "                          )\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs = 15,\n",
        "    batch_size = 128,\n",
        "    validation_split = .15,\n",
        "    callbacks = [EarlyStopping(patience= 2), checkpoint]\n",
        "\n",
        "\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.6412 - accuracy: 0.8158 - val_loss: 0.1565 - val_accuracy: 0.9579\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.15645, saving model to hamdwriting/model_weights\n",
            "Epoch 2/15\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.1418 - accuracy: 0.9582 - val_loss: 0.1155 - val_accuracy: 0.9661\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.15645 to 0.11554, saving model to hamdwriting/model_weights\n",
            "Epoch 3/15\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9717 - val_loss: 0.1198 - val_accuracy: 0.9647\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.11554\n",
            "Epoch 4/15\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0722 - accuracy: 0.9798 - val_loss: 0.0930 - val_accuracy: 0.9716\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.11554 to 0.09304, saving model to hamdwriting/model_weights\n",
            "Epoch 5/15\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0508 - accuracy: 0.9848 - val_loss: 0.0837 - val_accuracy: 0.9753\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.09304 to 0.08366, saving model to hamdwriting/model_weights\n",
            "Epoch 6/15\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9881 - val_loss: 0.0869 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.08366\n",
            "Epoch 7/15\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9896 - val_loss: 0.0866 - val_accuracy: 0.9747\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.08366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f95624b2290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n22slxQ_uWA0",
        "outputId": "41675312-222f-4cf3-8e81-e64c5638f02a"
      },
      "source": [
        "! ls hamdwriting"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint  model_weights.data-00000-of-00001  model_weights.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "ibt2DjCkD8Kn",
        "outputId": "17507b8c-aa5d-4ad3-d217-8ca4c74e0e9a"
      },
      "source": [
        "model_weights.data-00000-of-00001"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-53-bcab91a0bb2d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model_weights.data-00000-of-00001\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid token\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFvP74eZuWEh",
        "outputId": "36cc7ef1-cd8c-4a86-961e-66b638689e02"
      },
      "source": [
        "model.load_weights(path)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f95622e8750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz1hqq7rDpY9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBuEVrCSDqKs"
      },
      "source": [
        "### Atready saved model in tensorflow: Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_FayM-uwVSc"
      },
      "source": [
        "from tensorflow.keras.applications import InceptionV3"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJxtYXd87QFt",
        "outputId": "89720c5d-777d-4511-fbf0-06ef661bbbfc"
      },
      "source": [
        "model = InceptionV3()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1CpMbLP7UMm",
        "outputId": "5ec53d0b-efb5-49d3-f2a2-7be47d759930"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,851,784\n",
            "Trainable params: 23,817,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCadepp57XHa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}